{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc3bdc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import os\n",
    "from convert import *\n",
    "import datetime\n",
    "import time\n",
    "import cvxpy as cp\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.covariance as skcov\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d8a6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_df = pd.read_csv(r'D:\\Capstone_Data\\cleaned\\hourly_data_bid_ask_foreign.csv')\n",
    "timestamps = [datetime.datetime.strptime(item[:-6], '%Y-%m-%d %H') for item in hourly_df.time_utc]\n",
    "symbols = np.unique([item[:12] for item in hourly_df.columns[1:]]).astype(str)\n",
    "\n",
    "mid_price_mat = np.zeros((len(timestamps), len(symbols)))\n",
    "bid_price_mat = np.zeros((len(timestamps), len(symbols)))\n",
    "ask_price_mat = np.zeros((len(timestamps), len(symbols)))\n",
    "\n",
    "#calculating mid prices\n",
    "for i in range(len(symbols)):\n",
    "    mid_price_mat[:, i] = (hourly_df[symbols[i]+'_bid'] + hourly_df[symbols[i]+'_ask'])/2\n",
    "    bid_price_mat[:, i] = hourly_df[symbols[i]+'_bid']\n",
    "    ask_price_mat[:, i] = hourly_df[symbols[i]+'_ask']\n",
    "    \n",
    "#calculating transaction cost percentage for buying or selling\n",
    "C = (ask_price_mat - mid_price_mat)/mid_price_mat\n",
    "\n",
    "#use mid price to get the returns\n",
    "rets = mid_price_mat[1:]/mid_price_mat[:-1] - 1\n",
    "\n",
    "#splitting the returns and timestamps for the training and test set\n",
    "train_rets = rets[:-20*23]\n",
    "test_rets = rets[-20*23:]\n",
    "\n",
    "train_ts = timestamps[:-20*23]\n",
    "test_ts = timestamps[-20*23:]\n",
    "\n",
    "#transaction cost for the training set\n",
    "train_C = C[1:-20*23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "319f4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pnl_stats(pnl, pnl_len):\n",
    "    '''\n",
    "    calculate annualized statistics\n",
    "    '''\n",
    "    \n",
    "    pnl = pnl[-pnl_len:]\n",
    "    pnl = pnl/pnl[0]\n",
    "    #standard deviation\n",
    "    rets = pnl[1:]/pnl[:-1] - 1\n",
    "    std = np.std(rets) * np.sqrt(23*252)\n",
    "    \n",
    "    #total return on investment\n",
    "    roi = np.power(pnl[-1], 23*252/len(pnl))-1\n",
    "    \n",
    "    #sharpe ratio \n",
    "    sr = roi/std\n",
    "    \n",
    "    return roi, std, sr\n",
    "    \n",
    "def sample_cov(rets):\n",
    "    return np.cov(rets.T, ddof=0)\n",
    "\n",
    "def shrunk_cov(rets, alpha):\n",
    "    return skcov.ShrunkCovariance(shrinkage=alpha).fit(train_rets).covariance_\n",
    "\n",
    "def LW_cov(rets):\n",
    "    return skcov.LedoitWolf().fit(rets).covariance_\n",
    "\n",
    "# def online_cov(rets, lb_window, alpha):\n",
    "#     n_iter = len(rets)-lb_window+1\n",
    "#     res = np.zeros((n_iter, 10, 10))\n",
    "#     for i in range(n_iter):\n",
    "#         lb_rets = rets[i:i+lb_window]\n",
    "#         if i == 0:\n",
    "#             res[i] = sample_cov(lb_rets)\n",
    "#         else:\n",
    "#             res[i] = (1-alpha)*sample_cov(lb_rets) + alpha*sample_cov(lb_rets)\n",
    "#     return res\n",
    "    \n",
    "def backtest(train_ts, train_rets, reb_freq, lb_window, cov_type, alpha=None, a_ol = None):\n",
    "    '''\n",
    "    Input:\n",
    "    train_ts: timestamps for plotting\n",
    "    train_rets: array of historical returns for backtesting\n",
    "    reb_freq: rebalancing frequency/holding period\n",
    "    lb_window: lookback window size\n",
    "    cov_type: types of covariance matrix\n",
    "    constrained: whether has the non-negativity constraint\n",
    "    \n",
    "    Output:\n",
    "    '''\n",
    "    time_plot = train_ts[lb_window:] #timestamps for plotting\n",
    "    n_iters = int((train_rets.shape[0] - lb_window)/reb_freq)+1\n",
    "    pnl = np.array([1]) #initialize portfolio pnl\n",
    "    all_weights = np.zeros((1,10)) #initialize portfoio weights to all 0\n",
    "    \n",
    "    #calculate the online covariance matrices if necessary\n",
    "        \n",
    "    error_percent = 0\n",
    "    for i in range(n_iters):\n",
    "        weights_prev = all_weights[-1]\n",
    "        #calculate mu and Sigma\n",
    "        lb_rets = train_rets[i*reb_freq : lb_window + i*reb_freq,:]\n",
    "        mu = np.mean(lb_rets, axis=0)\n",
    "        if cov_type == 'sample':\n",
    "            Sigma = sample_cov(lb_rets)\n",
    "        elif cov_type == 'shrunk':\n",
    "            Sigma = shrunk_cov(lb_rets, alpha)\n",
    "        elif cov_type == 'LedoitWolf':\n",
    "            Sigma = LW_cov(lb_rets)\n",
    "        elif cov_type == 'online':\n",
    "            if i == 0:\n",
    "                Sigma = sample_cov(lb_rets)\n",
    "            else:\n",
    "                Sigma = (1-a_ol)*sample_cov(lb_rets) + a_ol * Sigma\n",
    "        \n",
    "        #C_curr = train_C[lb_window+i*reb_freq-1] #the transaction cost matrix\n",
    "        C_curr = np.zeros((10,))\n",
    "        \n",
    "        #performing Markowitz\n",
    "        \n",
    "        if np.any(Sigma==0):\n",
    "            weights = all_weights[-1]\n",
    "        else:\n",
    "            Sigma_ = 1/np.min(np.abs(Sigma)) * Sigma\n",
    "            w = cp.Variable(10)\n",
    "            risk = cp.quad_form(w, Sigma_)\n",
    "            ret = mu.T @ w\n",
    "            trans_cost = cp.abs(w-weights_prev) @ C_curr\n",
    "            kappa = 1\n",
    "            obj = risk\n",
    "            prob = cp.Problem(cp.Minimize(obj), [cp.sum(w) == 1, w>=0])\n",
    "            try:\n",
    "                prob.solve(solver='OSQP')\n",
    "                weights = w.value\n",
    "            except:\n",
    "                try:\n",
    "                    prob.solve(solver='ECOS')\n",
    "                    weights = w.value\n",
    "                except:\n",
    "                    try:\n",
    "                        prob.solve(solver='ECOS_BB')\n",
    "                        weights = w.value\n",
    "                    except:\n",
    "                        try:\n",
    "                            prob.solve(solver='SCS')\n",
    "                            weights = w.value\n",
    "                        except:\n",
    "                            weights = all_weights[-1]\n",
    "                            error_percent += 1/n_iters\n",
    "        \n",
    "        all_weights[-1] = weights\n",
    "        \n",
    "        #net the transaction cost\n",
    "        pnl_post_reb = pnl[-1] - np.abs(weights-weights_prev)*pnl[-1] @ C_curr #pnl after rebalancing\n",
    "        pnl[-1] = pnl_post_reb #updating\n",
    "        \n",
    "        #calculating weights and pnl in the validation set\n",
    "        valid_rets = train_rets[lb_window + i*reb_freq : lb_window+(i+1)*reb_freq,:]\n",
    "        valid_pnl = pnl_post_reb*weights*np.cumprod(1+valid_rets, axis=0) #the pnl in each currency\n",
    "        total_pnl = np.sum(valid_pnl, axis=1)\n",
    "        valid_weights = valid_pnl/np.repeat(total_pnl,10).reshape(valid_pnl.shape)\n",
    "        \n",
    "        #updating the weights & pnl in the valid set\n",
    "        all_weights = np.vstack((all_weights, valid_weights))\n",
    "        pnl = np.hstack((pnl, total_pnl))\n",
    "    \n",
    "    #plotting the pnl and save\n",
    "    plt.plot(time_plot, pnl, label='M.V. Port')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    if cov_type == 'shrunk':\n",
    "        plt.savefig(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\{}\\pnl\\LB{} HP{}.png'.format(cov_type, alpha, lb_window, reb_freq))\n",
    "    elif cov_type == 'online':\n",
    "        plt.savefig(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\{}\\pnl\\LB{} HP{}.png'.format(cov_type, a_ol, lb_window, reb_freq))\n",
    "    else:\n",
    "        plt.savefig(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\pnl\\LB{} HP{}.png'.format(cov_type, lb_window, reb_freq))\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    #plotting the portfolio weights\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.stackplot(time_plot, all_weights.T, labels = [symbol[:3] for symbol in symbols])\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    if cov_type == 'shrunk':\n",
    "        plt.savefig(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\{}\\weights\\LB{} HP{}.png'.format(cov_type, alpha, lb_window, reb_freq))\n",
    "    elif cov_type == 'online':\n",
    "        plt.savefig(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\{}\\weights\\LB{} HP{}.png'.format(cov_type, a_ol, lb_window, reb_freq))\n",
    "    else:\n",
    "        plt.savefig(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\weights\\LB{} HP{}.png'.format(cov_type, lb_window, reb_freq))\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    return all_weights, pnl, error_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "565d6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the set of parameters\n",
    "lb_windows = np.arange(20,250,10)\n",
    "reb_freqs = np.arange(1,21,1)\n",
    "\n",
    "standard_pnl_len = len(train_ts) - max(lb_windows)\n",
    "\n",
    "xdata_hm = [] \n",
    "ydata_hm = [] #for plotting\n",
    "\n",
    "#getting the x & y axis ready for plotting\n",
    "for lb_window in lb_windows:\n",
    "    for reb_freq in reb_freqs:\n",
    "        xdata_hm.append(lb_window)\n",
    "        ydata_hm.append(reb_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44472a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running backtest for sample covariance\n",
    "cov_type = 'sample'\n",
    "roi_stats = []\n",
    "std_stats = []\n",
    "sr_stats = []\n",
    "error_stats = []\n",
    "configs = []\n",
    "\n",
    "for lb_window in lb_windows:\n",
    "    for reb_freq in reb_freqs:\n",
    "        configs.append('LB:{} HP:{}'.format(lb_window, reb_freq))\n",
    "        _, pnl, error_percent = backtest(train_ts, train_rets, reb_freq, lb_window, cov_type)\n",
    "        roi, std, sr = pnl_stats(pnl, standard_pnl_len)\n",
    "        roi_stats.append(roi)\n",
    "        std_stats.append(std)\n",
    "        sr_stats.append(sr)\n",
    "        error_stats.append(error_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a9da181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame({'Configurations': configs, 'ROI': roi_stats, 'STD': std_stats, 'SR': sr_stats, 'ERR': error_stats})\n",
    "df_out.to_csv(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\summary.csv'.format(cov_type), index=False)\n",
    "    \n",
    "#plot the heat map\n",
    "data_plot = pd.DataFrame({'Lookback Window': xdata_hm, 'Holding Period': ydata_hm, \n",
    "                          'ROI': roi_stats, 'STD': std_stats, 'SR': sr_stats, 'ERR': error_stats})\n",
    "for metric in ['ROI', 'STD', 'SR', 'ERR']:\n",
    "    if metric == 'STD':\n",
    "        #ax = sns.heatmap(data_plot.pivot('Lookback Window', 'Holding Period', metric), vmin=0.05, vmax=0.1)\n",
    "        ax = sns.heatmap(data_plot.pivot('Lookback Window', 'Holding Period', metric))\n",
    "    else:\n",
    "        ax = sns.heatmap(data_plot.pivot('Lookback Window', 'Holding Period', metric))\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(cov_type+metric)\n",
    "    plt.savefig(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\heatmaps\\{}.png'.format(cov_type, metric))\n",
    "    plt.clf()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4550d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running backtest for shrunk covariance matrix\n",
    "cov_type = 'shrunk'\n",
    "alphas = np.round(np.arange(0.1,0.6,0.1),1)\n",
    "for alpha in alphas:\n",
    "    roi_stats = []\n",
    "    std_stats = []\n",
    "    sr_stats = []\n",
    "    error_stats = []\n",
    "    configs = []\n",
    "    for lb_window in lb_windows:\n",
    "        for reb_freq in reb_freqs:\n",
    "            configs.append('LB:{} HP:{}'.format(lb_window, reb_freq))\n",
    "            _, pnl, error_percent = backtest(train_ts, train_rets, reb_freq, lb_window, cov_type, alpha)\n",
    "            roi, std, sr = pnl_stats(pnl, standard_pnl_len)\n",
    "            roi_stats.append(roi)\n",
    "            std_stats.append(std)\n",
    "            sr_stats.append(sr)\n",
    "            error_stats.append(error_percent)\n",
    "\n",
    "    #save the summary statisitics in a csv file\n",
    "    df_out = pd.DataFrame({'Configurations': configs, 'ROI': roi_stats, 'STD': std_stats, 'SR': sr_stats, 'ERR': error_stats})\n",
    "    df_out.to_csv(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\{}\\summary.csv'.format(cov_type, alpha), index=False)\n",
    "\n",
    "    #plot the heat map\n",
    "    data_plot = pd.DataFrame({'Lookback Window': xdata_hm, 'Holding Period': ydata_hm, \n",
    "                              'ROI': roi_stats, 'STD': std_stats, 'SR': sr_stats, 'ERR': error_stats})\n",
    "    for metric in ['ROI', 'STD', 'SR', 'ERR']:\n",
    "        if metric == 'STD':\n",
    "            ax = sns.heatmap(data_plot.pivot('Lookback Window', 'Holding Period', metric), vmin=0.05, vmax=0.1)\n",
    "        else:\n",
    "            ax = sns.heatmap(data_plot.pivot('Lookback Window', 'Holding Period', metric))\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_title(cov_type+metric)\n",
    "        plt.savefig(r'D:\\Capstone_Data\\result_daily\\{}\\{}\\heatmaps\\{}.png'.format(cov_type, alpha, metric))\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d128eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running backtest for LedoitWolf covariance\n",
    "cov_type = 'LedoitWolf'\n",
    "roi_stats = []\n",
    "std_stats = []\n",
    "sr_stats = []\n",
    "error_stats = []\n",
    "configs = []\n",
    "\n",
    "for lb_window in lb_windows:\n",
    "    for reb_freq in reb_freqs:\n",
    "        configs.append('LB:{} HP:{}'.format(lb_window, reb_freq))\n",
    "        _, pnl, error_percent = backtest(train_ts, train_rets, reb_freq, lb_window, cov_type)\n",
    "        roi, std, sr = pnl_stats(pnl, standard_pnl_len)\n",
    "        roi_stats.append(roi)\n",
    "        std_stats.append(std)\n",
    "        sr_stats.append(sr)\n",
    "        error_stats.append(error_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c35e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the summary statisitics in a csv file\n",
    "df_out = pd.DataFrame({'Configurations': configs, 'ROI': roi_stats, 'STD': std_stats, 'SR': sr_stats, 'ERR': error_stats})\n",
    "df_out.to_csv(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\summary.csv'.format(cov_type), index=False)\n",
    "    \n",
    "#plot the heat map\n",
    "data_plot = pd.DataFrame({'Lookback Window': xdata_hm, 'Holding Period': ydata_hm, \n",
    "                          'ROI': roi_stats, 'STD': std_stats, 'SR': sr_stats, 'ERR': error_stats})\n",
    "for metric in ['ROI', 'STD', 'SR', 'ERR']:\n",
    "    if metric == 'STD':\n",
    "        #ax = sns.heatmap(data_plot.pivot('Lookback Window', 'Holding Period', metric), vmin=0.05, vmax=0.1)\n",
    "        ax = sns.heatmap(data_plot.pivot('Lookback Window', 'Holding Period', metric))\n",
    "    else:\n",
    "        ax = sns.heatmap(data_plot.pivot('Lookback Window', 'Holding Period', metric))\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(cov_type+metric)\n",
    "    plt.savefig(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\heatmaps\\{}.png'.format(cov_type, metric))\n",
    "    plt.clf()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af8055b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running backtest for online covariance\n",
    "cov_type = 'online'\n",
    "a_ol = 0.01\n",
    "roi_stats = []\n",
    "std_stats = []\n",
    "sr_stats = []\n",
    "error_stats = []\n",
    "configs = []\n",
    "\n",
    "for lb_window in lb_windows:\n",
    "    for reb_freq in reb_freqs:\n",
    "        configs.append('LB:{} HP:{}'.format(lb_window, reb_freq))\n",
    "        _, pnl, error_percent = backtest(train_ts, train_rets, reb_freq, lb_window, cov_type, a_ol=a_ol)\n",
    "        roi, std, sr = pnl_stats(pnl, standard_pnl_len)\n",
    "        roi_stats.append(roi)\n",
    "        std_stats.append(std)\n",
    "        sr_stats.append(sr)\n",
    "        error_stats.append(error_percent)\n",
    "        \n",
    "#save the summary statisitics in a csv file\n",
    "df_out = pd.DataFrame({'Configurations': configs, 'ROI': roi_stats, 'STD': std_stats, 'SR': sr_stats, 'ERR': error_stats})\n",
    "df_out.to_csv(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\{}\\summary.csv'.format(cov_type, a_ol), index=False)\n",
    "    \n",
    "#plot the heat map\n",
    "data_plot = pd.DataFrame({'Lookback Window': xdata_hm, 'Holding Period': ydata_hm, \n",
    "                          'ROI': roi_stats, 'STD': std_stats, 'SR': sr_stats, 'ERR': error_stats})\n",
    "for metric in ['ROI', 'STD', 'SR', 'ERR']:\n",
    "    if metric == 'STD':\n",
    "        #ax = sns.heatmap(data_plot.pivot('Lookback Window', 'Holding Period', metric), vmin=0.05, vmax=0.1)\n",
    "        ax = sns.heatmap(data_plot.pivot('Lookback Window', 'Holding Period', metric))\n",
    "    else:\n",
    "        ax = sns.heatmap(data_plot.pivot('Lookback Window', 'Holding Period', metric))\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(cov_type+metric)\n",
    "    plt.savefig(r'D:\\Capstone_Data\\result_hourly_without_mu\\{}\\{}\\heatmaps\\{}.png'.format(cov_type, a_ol, metric))\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02fcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bda22",
   "language": "python",
   "name": "bda22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
